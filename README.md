# ðŸ“„ LLM Extraction Pipeline

This project extracts structured data from carrier contract PDFs using OCR and the Gemini API. The flow includes reading PDF files, extracting tables and text, processing them with LLM prompts, and organizing the results in a nested data structure.

## ðŸ§± Project Structure

LLM_Extraction/
â”‚
â”œâ”€â”€ main.py # Main pipeline entry
â”œâ”€â”€ setup.py # Loads environment variables & config
â”œâ”€â”€ data_extraction.py # PDF partitioning and OCR using Unstructured
â”œâ”€â”€ gemini_api.py # Gemini API call and prompt formatting
â”œâ”€â”€ data_structure.py # Adds entries to the nested structure
â”œâ”€â”€ try_fix.py # Utility to fix malformed JSON from LLM
â”œâ”€â”€ .env # API keys and config (not tracked by Git)
â”œâ”€â”€ .gitignore # Ignore config and cache files
â”œâ”€â”€ requirements.txt # Python dependencies
â”œâ”€â”€ README.md # This file


## ðŸš€ How to Run

1. Clone the repo and set up a virtual environment:
    ```bash
    python -m venv venv
    venv\Scripts\activate   # For Windows
    pip install -r requirements.txt
    ```

2. Create a `.env` file with:
    ```env
    GEMINI_API_KEY=your-api-key-here
    TESSERACT_PATH=full/path/to/tesseract.exe
    PDF_PATH=full/path/to/your_pdf.pdf
    ```

3. Run the pipeline:
    ```bash
    python main.py
    ```

## ðŸ“¦ Requirements

- Python 3.8+
- Tesseract OCR installed
- Google Gemini API key

## ðŸ§  What it does

- Segments PDF into text and tables
- Sends chunks to Gemini API
- Structures results into `location_data`
- Handles malformed JSON responses

## ðŸ“‚ Output

Prints structured nested dictionary of locations and extracted info.

---
